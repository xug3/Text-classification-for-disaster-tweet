{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#install sentence_transformers\n#pip install sentence_transformers","metadata":{"execution":{"iopub.status.busy":"2022-03-09T22:24:32.972333Z","iopub.execute_input":"2022-03-09T22:24:32.972662Z","iopub.status.idle":"2022-03-09T22:24:45.046035Z","shell.execute_reply.started":"2022-03-09T22:24:32.972618Z","shell.execute_reply":"2022-03-09T22:24:45.04533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sentence_transformers import SentenceTransformer\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport xgboost as xgb\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier\nimport matplotlib.pyplot as plt \nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.linear_model import SGDClassifier","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-09T23:42:46.357281Z","iopub.execute_input":"2022-03-09T23:42:46.357953Z","iopub.status.idle":"2022-03-09T23:42:46.363854Z","shell.execute_reply.started":"2022-03-09T23:42:46.357908Z","shell.execute_reply":"2022-03-09T23:42:46.363241Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"#Read the data\ndisastertweets=pd.read_csv(\"../input/nlp-getting-started/train.csv\")\ndisastertweets.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-09T23:24:11.864403Z","iopub.execute_input":"2022-03-09T23:24:11.864652Z","iopub.status.idle":"2022-03-09T23:24:11.903174Z","shell.execute_reply.started":"2022-03-09T23:24:11.864626Z","shell.execute_reply":"2022-03-09T23:24:11.902576Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"   id keyword location                                               text  \\\n0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n\n   target  \n0       1  \n1       1  \n2       1  \n3       1  \n4       1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Our Deeds are the Reason of this #earthquake M...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Forest fire near La Ronge Sask. Canada</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>All residents asked to 'shelter in place' are ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>13,000 people receive #wildfires evacuation or...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#assign text data to a pandas series textvector\n#assign disaster resutls to target (responds)\ntextvector=disastertweets[\"text\"]\ntarget=disastertweets[\"target\"]\ntextvector.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-09T23:24:22.249682Z","iopub.execute_input":"2022-03-09T23:24:22.249950Z","iopub.status.idle":"2022-03-09T23:24:22.259478Z","shell.execute_reply.started":"2022-03-09T23:24:22.249923Z","shell.execute_reply":"2022-03-09T23:24:22.258609Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"0    Our Deeds are the Reason of this #earthquake M...\n1               Forest fire near La Ronge Sask. Canada\n2    All residents asked to 'shelter in place' are ...\n3    13,000 people receive #wildfires evacuation or...\n4    Just got sent this photo from Ruby #Alaska as ...\nName: text, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"#count cases, cases proportion, and total number in the data\nprint(\"Number of case is {}, the proportion of case is {}, and the total number is {}\".format(np.sum(target),\n      len(target),np.sum(target)/len(target)))","metadata":{"execution":{"iopub.status.busy":"2022-03-09T23:24:35.653674Z","iopub.execute_input":"2022-03-09T23:24:35.653961Z","iopub.status.idle":"2022-03-09T23:24:35.659607Z","shell.execute_reply.started":"2022-03-09T23:24:35.653927Z","shell.execute_reply":"2022-03-09T23:24:35.659045Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Number of case is 3271, the proportion of case is 7613, and the total number is 0.4296597924602653\n","output_type":"stream"}]},{"cell_type":"code","source":"#count how many words in each sentense\ncounts=textvector.apply(lambda x: len(x.split()))","metadata":{"execution":{"iopub.status.busy":"2022-03-09T23:24:46.771158Z","iopub.execute_input":"2022-03-09T23:24:46.771476Z","iopub.status.idle":"2022-03-09T23:24:46.788623Z","shell.execute_reply.started":"2022-03-09T23:24:46.771445Z","shell.execute_reply":"2022-03-09T23:24:46.787582Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#histgram for counts\ncounts.plot.hist()\nmin_num=counts.min()\nmax_num=counts.max()\nprint(\"The minimun number word in a sentense is {} and the maximun number of words is {}\".format(min_num,max_num))","metadata":{"execution":{"iopub.status.busy":"2022-03-09T23:25:04.761909Z","iopub.execute_input":"2022-03-09T23:25:04.762219Z","iopub.status.idle":"2022-03-09T23:25:05.045868Z","shell.execute_reply.started":"2022-03-09T23:25:04.762184Z","shell.execute_reply":"2022-03-09T23:25:05.045010Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"The minimun number word in a sentense is 1 and the maximun number of words is 31\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAYsAAAD4CAYAAAAdIcpQAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAUkklEQVR4nO3dfbAldX3n8ffHAUVI4oBMCDsz5KKhzBLjxskIpExSrqzIQ+KQKkOgkjghJJMtMatLqnRkt4JryircTURJJWxGmRWyRmQRZXYhwQmSuKlaHgZEHmOY4CAzAnOVJwlGFv3uH+c3y3G8d/rM5Z5z7rn3/ao6dbp/3af729XM/dC/fkpVIUnSvrxo3AVIkhY+w0KS1MmwkCR1MiwkSZ0MC0lSpwPGXcAwHH744TU1NTXuMiRpotx2221fr6oVM01blGExNTXFtm3bxl2GJE2UJA/ONs1uKElSJ8NCktTJsJAkdTIsJEmdDAtJUifDQpLUybCQJHUyLCRJnQwLSVKnRXkHt7SQTW28dizr3XHhaWNZrxYHjywkSZ2GFhZJNifZneTuGab9XpJKcngbT5KLk2xPcmeSNX3zrk9yf/usH1a9kqTZDfPI4uPAyXs3JlkNnAR8ta/5FOCY9tkAXNLmPQy4ADgeOA64IMmhQ6xZkjSDoYVFVX0BeGyGSRcB7waqr20dcHn13AQsT3Ik8GZga1U9VlWPA1uZIYAkScM10nMWSdYBu6rqS3tNWgk81De+s7XN1j7Tsjck2ZZk2/T09DxWLUkaWVgkORg4H/j9YSy/qjZV1dqqWrtixYzv7pAkzdEojyxeCRwNfCnJDmAVcHuSHwF2Aav75l3V2mZrlySN0MjCoqruqqofrqqpqpqi16W0pqoeAbYAb2tXRZ0APFlVDwPXAyclObSd2D6ptUmSRmiYl85+Evg/wKuS7Exyzj5mvw54ANgOfBR4O0BVPQb8AXBr+7y/tUmSRmhod3BX1Vkd06f6hgs4d5b5NgOb57U4SdJ+8Q5uSVInw0KS1MmwkCR1MiwkSZ0MC0lSJ8NCktTJlx9pSRrXC4ikSeWRhSSpk2EhSepkWEiSOhkWkqROhoUkqZNhIUnqZFhIkjoZFpKkToaFJKmTd3BrrLyTWpoMHllIkjoZFpKkToaFJKnT0MIiyeYku5Pc3df2X5L8fZI7k3wmyfK+ae9Nsj3Jl5O8ua/95Na2PcnGYdUrSZrdMI8sPg6cvFfbVuDVVfUa4B+A9wIkORY4E/iJ9ps/TbIsyTLgT4BTgGOBs9q8kqQRGlpYVNUXgMf2avtcVT3XRm8CVrXhdcAVVfXtqvoKsB04rn22V9UDVfUscEWbV5I0QuM8Z/GbwF+24ZXAQ33Tdra22dq/T5INSbYl2TY9PT2EciVp6RpLWCT5D8BzwCfma5lVtamq1lbV2hUrVszXYiVJjOGmvCS/AfwCcGJVVWveBazum21Va2Mf7ZKkERnpkUWSk4F3A2+pqmf6Jm0BzkzykiRHA8cAtwC3AsckOTrJi+mdBN8yypolSUM8skjySeANwOFJdgIX0Lv66SXA1iQAN1XVv62qe5JcCdxLr3vq3Kr6TlvOO4DrgWXA5qq6Z1g1S5JmNrSwqKqzZmi+dB/zfwD4wAzt1wHXzWNpkqT95B3ckqROhoUkqZNhIUnqZFhIkjoZFpKkToaFJKmTYSFJ6mRYSJI6GRaSpE4jf5CgpPGY2njt2Na948LTxrZuzQ+PLCRJnQwLSVInw0KS1MmwkCR1MiwkSZ0MC0lSJ8NCktTJsJAkdTIsJEmdDAtJUqehhUWSzUl2J7m7r+2wJFuT3N++D23tSXJxku1J7kyypu8369v89ydZP6x6JUmzG+aRxceBk/dq2wjcUFXHADe0cYBTgGPaZwNwCfTCBbgAOB44DrhgT8BIkkZnaGFRVV8AHtureR1wWRu+DDi9r/3y6rkJWJ7kSODNwNaqeqyqHge28v0BJEkaslGfsziiqh5uw48AR7ThlcBDffPtbG2ztX+fJBuSbEuybXp6en6rlqQlbmwnuKuqgJrH5W2qqrVVtXbFihXztVhJEqMPi0db9xLte3dr3wWs7ptvVWubrV2SNEKjDostwJ4rmtYD1/S1v61dFXUC8GTrrroeOCnJoe3E9kmtTZI0QkN7U16STwJvAA5PspPeVU0XAlcmOQd4EDijzX4dcCqwHXgGOBugqh5L8gfArW2+91fV3ifNJUlDNrSwqKqzZpl04gzzFnDuLMvZDGyex9IkSfvJO7glSZ0MC0lSJ8NCktTJsJAkdTIsJEmdDAtJUqeBwiLJTw67EEnSwjXokcWfJrklyduTvGyoFUmSFpyBwqKqfg74VXrPabotyV8kedNQK5MkLRgD38FdVfcn+Y/ANuBi4LVJApxfVVcPq0CNxtTGa8ddgqQFbNBzFq9JchFwH/BG4Ber6l+24YuGWJ8kaQEY9Mjij4GP0TuK+Naexqr6WjvakCQtYoOGxWnAt6rqOwBJXgQcVFXPVNWfD606SdKCMOjVUH8NvLRv/ODWJklaAgYNi4Oq6uk9I2344OGUJElaaAYNi39KsmbPSJKfBr61j/klSYvIoOcs3gX8jyRfAwL8CPArwypKkrSwDBQWVXVrkh8HXtWavlxV/3d4ZUmSFpL9ea3q64Cp9ps1Saiqy4dSlSRpQRkoLJL8OfBK4A7gO625AMNCkpaAQY8s1gLHVlXNx0qT/Hvgt+gFzl3A2cCRwBXAy4HbgF+vqmeTvIReKP008A3gV6pqx3zUIUkazKBXQ91N76T2C5ZkJfDvgLVV9WpgGXAm8EHgoqr6MeBx4Jz2k3OAx1v7RW0+SdIIDRoWhwP3Jrk+yZY9nxew3gOAlyY5gN79Gg/Te87UVW36ZcDpbXhdG6dNP7E9wFCSNCKDdkO9b75WWFW7kvwh8FV692p8jl630xNV9VybbSewsg2vBB5qv30uyZP0uqq+3r/cJBuADQBHHXXUfJUrSWLw91n8LbADOLAN3wrcPpcVJjmU3tHC0cC/AA4BTp7LsvaqcVNVra2qtStWrHihi5Mk9Rn0EeW/Ta8L6M9a00rgs3Nc578BvlJV0+1ejauB1wPLW7cUwCpgVxveRe+lS7TpL6N3oluSNCKDnrM4l94f9Keg9yIk4IfnuM6vAickObidezgRuBe4EXhrm2c9cE0b3tLGadM/P19XZUmSBjNoWHy7qp7dM9L+D39Of7Cr6mZ6Rym307ts9kXAJuA9wHlJttM7J3Fp+8mlwMtb+3nAxrmsV5I0d4Oe4P7bJOfTu4LpTcDbgf8515VW1QXABXs1PwAcN8O8/wz88lzXJUl64QY9stgITNM7Evgd4DrAN+RJ0hIx6IMEvwt8tH0kSUvMoM+G+goznKOoqlfMe0WSpAVnf54NtcdB9M4hHDb/5UiSFqJBb8r7Rt9nV1V9GDhtuKVJkhaKQbuh1vSNvojekcb+vAtDkjTBBv2D/0d9w8/Re/THGfNejSRpQRr0aqh/PexCJEkL16DdUOfta3pVfWh+ypEkLUT7czXU6+g9pwngF4FbgPuHUZQkaWEZNCxWAWuq6psASd4HXFtVvzaswiQtHlMbrx3Lendc6EWb82XQx30cATzbN/5sa5MkLQGDHllcDtyS5DNt/HSef9WpJGmRG/RqqA8k+Uvg51rT2VX1xeGVJUlaSAbthgI4GHiqqj4C7Exy9JBqkiQtMIO+VvUCei8nem9rOhD478MqSpK0sAx6ZPFLwFuAfwKoqq8BPzisoiRJC8ugYfFse+91ASQ5ZHglSZIWmkHD4sokfwYsT/LbwF/ji5AkacnoDIskAT4FXAV8GngV8PtV9cdzXWmS5UmuSvL3Se5L8jNJDkuyNcn97fvQPetPcnGS7Unu3OsJuJKkEei8dLaqKsl1VfWTwNZ5Wu9HgL+qqrcmeTG9K63OB26oqguTbKT33u/3AKcAx7TP8cAl7VuSNCKDdkPdnuR187HCJC8Dfh64FKCqnq2qJ4B1PH+j32X0bvyjtV9ePTfR6wo7cj5qkSQNZtCwOB64Kck/tq6gu5LcOcd1Hg1MA/8tyReTfKydMD+iqh5u8zzC848TWQk81Pf7na3teyTZkGRbkm3T09NzLE2SNJN9dkMlOaqqvgq8eZ7XuQb43aq6OclH6HU5/X+t66v2Z6FVtQnYBLB27dr9+q0kad+6jiw+C1BVDwIfqqoH+z9zXOdOYGdV3dzGr6IXHo/u6V5q37vb9F3A6r7fr2ptkqQR6QqL9A2/Yj5WWFWPAA8leVVrOhG4l967Mta3tvXANW14C/C2dlXUCcCTfd1VkqQR6LoaqmYZfqF+F/hEuxLqAeBsesF1ZZJzgAd5/h3f1wGnAtuBZ9q8kqQR6gqLf5XkKXpHGC9tw7TxqqofmstKq+oOem/f29uJM8xbwLlzWY8kaX7sMyyqatmoCpEkLVz784hySdISZVhIkjoZFpKkToaFJKmTYSFJ6mRYSJI6GRaSpE6GhSSpk2EhSepkWEiSOhkWkqROhoUkqZNhIUnqZFhIkjp1vc9CIzS18dpxlyBJM/LIQpLUybCQJHUyLCRJnQwLSVKnsYVFkmVJvpjkf7Xxo5PcnGR7kk8leXFrf0kb396mT42rZklaqsZ5ZPFO4L6+8Q8CF1XVjwGPA+e09nOAx1v7RW0+SdIIjSUskqwCTgM+1sYDvBG4qs1yGXB6G17XxmnTT2zzS5JGZFxHFh8G3g18t42/HHiiqp5r4zuBlW14JfAQQJv+ZJv/eyTZkGRbkm3T09NDLF2Slp6Rh0WSXwB2V9Vt87ncqtpUVWurau2KFSvmc9GStOSN4w7u1wNvSXIqcBDwQ8BHgOVJDmhHD6uAXW3+XcBqYGeSA4CXAd8YfdmStHSN/Miiqt5bVauqago4E/h8Vf0qcCPw1jbbeuCaNryljdOmf76qaoQlS9KSt5Dus3gPcF6S7fTOSVza2i8FXt7azwM2jqk+SVqyxvogwar6G+Bv2vADwHEzzPPPwC+PtDBJ0vdYSEcWkqQFyrCQJHUyLCRJnQwLSVInw0KS1MmwkCR1MiwkSZ0MC0lSJ8NCktTJsJAkdRrr4z4kaZimNl47tnXvuPC0sa17GDyykCR1MiwkSZ0MC0lSJ8NCktTJsJAkdTIsJEmdDAtJUifDQpLUybCQJHUaeVgkWZ3kxiT3JrknyTtb+2FJtia5v30f2tqT5OIk25PcmWTNqGuWpKVuHEcWzwG/V1XHAicA5yY5FtgI3FBVxwA3tHGAU4Bj2mcDcMnoS5akpW3kYVFVD1fV7W34m8B9wEpgHXBZm+0y4PQ2vA64vHpuApYnOXK0VUvS0jbWcxZJpoDXAjcDR1TVw23SI8ARbXgl8FDfz3a2tr2XtSHJtiTbpqenh1e0JC1BYwuLJD8AfBp4V1U91T+tqgqo/VleVW2qqrVVtXbFihXzWKkkaSxhkeRAekHxiaq6ujU/uqd7qX3vbu27gNV9P1/V2iRJIzKOq6ECXArcV1Uf6pu0BVjfhtcD1/S1v61dFXUC8GRfd5UkaQTG8fKj1wO/DtyV5I7Wdj5wIXBlknOAB4Ez2rTrgFOB7cAzwNkjrVaSNPqwqKq/AzLL5BNnmL+Ac4dalCRpn7yDW5LUybCQJHUyLCRJnQwLSVInw0KS1MmwkCR1Gsd9Fgve1MZrx12CJC0oHllIkjoZFpKkToaFJKmTYSFJ6mRYSJI6GRaSpE6GhSSpk/dZSNIQjOt+rR0XnjaU5XpkIUnqZFhIkjoZFpKkToaFJKmTYSFJ6jQxYZHk5CRfTrI9ycZx1yNJS8lEhEWSZcCfAKcAxwJnJTl2vFVJ0tIxEWEBHAdsr6oHqupZ4Apg3ZhrkqQlY1JuylsJPNQ3vhM4vn+GJBuADW306SRfnmE5hwNfH0qFo7VYtgPcloVosWwHLMFtyQdf0Dp+dLYJkxIWnapqE7BpX/Mk2VZVa0dU0tAslu0At2UhWizbAW7LfJqUbqhdwOq+8VWtTZI0ApMSFrcCxyQ5OsmLgTOBLWOuSZKWjInohqqq55K8A7geWAZsrqp75rCofXZTTZDFsh3gtixEi2U7wG2ZN6mqca5fkjQBJqUbSpI0RoaFJKnTkgiLxfSokCQ7ktyV5I4k28Zdz/5IsjnJ7iR397UdlmRrkvvb96HjrHEQs2zH+5LsavvljiSnjrPGQSVZneTGJPcmuSfJO1v7JO6X2bZlovZNkoOS3JLkS207/lNrPzrJze3v2KfaxT6jq2uxn7Nojwr5B+BN9G7muxU4q6ruHWthc5RkB7C2qibuRqMkPw88DVxeVa9ubf8ZeKyqLmxBfmhVvWecdXaZZTveBzxdVX84ztr2V5IjgSOr6vYkPwjcBpwO/AaTt19m25YzmKB9kyTAIVX1dJIDgb8D3gmcB1xdVVck+a/Al6rqklHVtRSOLHxUyAJRVV8AHtureR1wWRu+jN4/7gVtlu2YSFX1cFXd3oa/CdxH74kJk7hfZtuWiVI9T7fRA9ungDcCV7X2ke+TpRAWMz0qZOL+A+pTwOeS3NYecTLpjqiqh9vwI8AR4yzmBXpHkjtbN9WC77bZW5Ip4LXAzUz4ftlrW2DC9k2SZUnuAHYDW4F/BJ6oqufaLCP/O7YUwmKx+dmqWkPvCbznti6RRaF6faKT2i96CfBK4KeAh4E/Gms1+ynJDwCfBt5VVU/1T5u0/TLDtkzcvqmq71TVT9F7WsVxwI+Pt6KlERaL6lEhVbWrfe8GPkPvP6RJ9mjra97T57x7zPXMSVU92v6Bfxf4KBO0X1q/+KeBT1TV1a15IvfLTNsyyfumqp4AbgR+BlieZM+N1CP/O7YUwmLRPCokySHtxB1JDgFOAu7e968WvC3A+ja8HrhmjLXM2Z4/rM0vMSH7pZ1MvRS4r6o+1Ddp4vbLbNsyafsmyYoky9vwS+ldnHMfvdB4a5tt5Ptk0V8NBdAulfswzz8q5APjrWhukryC3tEE9B7V8heTtC1JPgm8gd6jlh8FLgA+C1wJHAU8CJxRVQv65PEs2/EGet0cBewAfqevz3/BSvKzwP8G7gK+25rPp9fXP2n7ZbZtOYsJ2jdJXkPvBPYyev9Df2VVvb/9+78COAz4IvBrVfXtkdW1FMJCkvTCLIVuKEnSC2RYSJI6GRaSpE6GhSSpk2EhSepkWEiSOhkWkqRO/w/2nDhjc7lMvAAAAABJRU5ErkJggg==\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"#Use BoW model convert text to sparse feature matrix\ncount_vect = CountVectorizer()\nx_train_counts= count_vect.fit_transform(textvector)\nx_train_counts.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-09T23:25:41.045250Z","iopub.execute_input":"2022-03-09T23:25:41.045658Z","iopub.status.idle":"2022-03-09T23:25:41.243654Z","shell.execute_reply.started":"2022-03-09T23:25:41.045610Z","shell.execute_reply":"2022-03-09T23:25:41.242838Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"(7613, 21637)"},"metadata":{}}]},{"cell_type":"code","source":"#use BERT to convert text to feature matrix\nmodel = SentenceTransformer('distilbert-base-nli-mean-tokens')\nembeddings = model.encode(textvector, show_progress_bar=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T23:28:09.399946Z","iopub.execute_input":"2022-03-09T23:28:09.400303Z","iopub.status.idle":"2022-03-09T23:32:31.446701Z","shell.execute_reply.started":"2022-03-09T23:28:09.400267Z","shell.execute_reply":"2022-03-09T23:32:31.446080Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/238 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c9dd26138ae4403a3629facb7c63d1f"}},"metadata":{}}]},{"cell_type":"code","source":"x_train_embeddings=np.array(embeddings)\nx_train_embeddings.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-09T23:34:52.952486Z","iopub.execute_input":"2022-03-09T23:34:52.952796Z","iopub.status.idle":"2022-03-09T23:34:52.966012Z","shell.execute_reply.started":"2022-03-09T23:34:52.952766Z","shell.execute_reply":"2022-03-09T23:34:52.965348Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"(7613, 768)"},"metadata":{}}]},{"cell_type":"code","source":"#Read the test data\ndisastertweets_test=pd.read_csv(\"../input/nlp-getting-started/test.csv\")\ndisastertweets_test.head()\n#convert test text to a test matrix\ntext_test = disastertweets_test[\"text\"]\nx_test_embeddings = model.encode(text_test, show_progress_bar=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T23:34:57.322949Z","iopub.execute_input":"2022-03-09T23:34:57.323505Z","iopub.status.idle":"2022-03-09T23:36:45.997103Z","shell.execute_reply.started":"2022-03-09T23:34:57.323462Z","shell.execute_reply":"2022-03-09T23:36:45.996133Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36d5f54913464e89914205e2c260e410"}},"metadata":{}}]},{"cell_type":"code","source":"x_test_embeddings=np.array(x_test_embeddings)\nx_test_embeddings.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-09T23:37:26.365159Z","iopub.execute_input":"2022-03-09T23:37:26.365477Z","iopub.status.idle":"2022-03-09T23:37:26.373134Z","shell.execute_reply.started":"2022-03-09T23:37:26.365444Z","shell.execute_reply":"2022-03-09T23:37:26.372302Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"(3263, 768)"},"metadata":{}}]},{"cell_type":"code","source":"x_test_counts= count_vect.transform(text_test)\nx_test_counts.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-09T23:37:28.256443Z","iopub.execute_input":"2022-03-09T23:37:28.256734Z","iopub.status.idle":"2022-03-09T23:37:28.314716Z","shell.execute_reply.started":"2022-03-09T23:37:28.256689Z","shell.execute_reply":"2022-03-09T23:37:28.313413Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"(3263, 21637)"},"metadata":{}}]},{"cell_type":"code","source":"#train a logistic classifier for embeddings\nLogistclf = LogisticRegression(penalty=\"l2\", max_iter=1000).fit(x_train_embeddings, target)\n#predict test data with logistic classifier\nLogistpredict = Logistclf.predict(x_test_embeddings)\n#Read the sample_submission\nsample_submission=pd.read_csv(\"../input/nlp-getting-started/sample_submission.csv\")\nsample_submission[\"target\"]=Logistpredict\n#write the reults\nsample_submission.to_csv(\"./BERT_Logist.csv\",index=False)\n#results report\n#Use BERT to convert features from text and use logistic classifier to classify target. \n#F1=2*precision*recall/(precision+recall)\n#where precision=TP/(TP+FP)\n#recall=TP/(TP+FN)\n#True Positive [TP] = your prediction is 1, and the ground truth is also 1 - you predicted a positive and that's true!\n#False Positive [FP] = your prediction is 1, and the ground truth is 0 - you predicted a positive, and that's false.\n#False Negative [FN] = your prediction is 0, and the ground truth is 1 - you predicted a negative, and that's false.\n#F1=0.8075","metadata":{"execution":{"iopub.status.busy":"2022-03-09T23:37:44.949584Z","iopub.execute_input":"2022-03-09T23:37:44.950032Z","iopub.status.idle":"2022-03-09T23:37:49.356337Z","shell.execute_reply.started":"2022-03-09T23:37:44.949999Z","shell.execute_reply":"2022-03-09T23:37:49.355351Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"#train a logistic classifier for sparse feature matrix from bow\nLogistclfBow = LogisticRegression(penalty=\"l2\", max_iter=1000).fit(x_train_counts, target)\n#predict test data with logistic classifier\nLogistpredictBow = LogistclfBow.predict(x_test_counts)\n#Read the sample_submission\nsample_submission=pd.read_csv(\"../input/nlp-getting-started/sample_submission.csv\")\nsample_submission[\"target\"]=LogistpredictBow\n#write the reults\nsample_submission.to_csv(\"./Bow_Logist.csv\",index=False)\n#results report\n#Use Bow to extract features from text and use logistic classifier to classify target. \n#F1=0.79987","metadata":{"execution":{"iopub.status.busy":"2022-03-09T23:38:45.579772Z","iopub.execute_input":"2022-03-09T23:38:45.580451Z","iopub.status.idle":"2022-03-09T23:38:47.067378Z","shell.execute_reply.started":"2022-03-09T23:38:45.580412Z","shell.execute_reply":"2022-03-09T23:38:47.066396Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"#train a naive Bayes classifier for embeddings\nNBclf = BernoulliNB().fit(x_train_embeddings, target)\n#predict test data\nNBpredict = NBclf.predict(x_test_embeddings)\n#Read the sample_submission\nsample_submission=pd.read_csv(\"../input/nlp-getting-started/sample_submission.csv\")\nsample_submission[\"target\"]=NBpredict\n#write the reults\nsample_submission.to_csv(\"./BERT_naiveBayes.csv\",index=False)\n#results report\n#Use BERT to convert features from text and use naive Bayes classifier to classify target. \n#F1=0.7440","metadata":{"execution":{"iopub.status.busy":"2022-03-09T23:40:03.004242Z","iopub.execute_input":"2022-03-09T23:40:03.004540Z","iopub.status.idle":"2022-03-09T23:40:03.246262Z","shell.execute_reply.started":"2022-03-09T23:40:03.004505Z","shell.execute_reply":"2022-03-09T23:40:03.244972Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"#train a naive Bayes classifier for sparse feature matrix from bow\nNBclfBow = BernoulliNB().fit(x_train_counts, target)\n#predict test data\nNBpredictBow = NBclfBow.predict(x_test_counts)\n#Read the sample_submission\nsample_submission=pd.read_csv(\"../input/nlp-getting-started/sample_submission.csv\")\nsample_submission[\"target\"]=NBpredictBow\n#write the reults\nsample_submission.to_csv(\"./Bow_naiveBayes.csv\",index=False)\n#results report\n#Use Bow to extract features matrix from text and use naive Bayes Bernoulli to classify target\n#F1=0.79406","metadata":{"execution":{"iopub.status.busy":"2022-03-09T23:41:51.489147Z","iopub.execute_input":"2022-03-09T23:41:51.489581Z","iopub.status.idle":"2022-03-09T23:41:51.510552Z","shell.execute_reply.started":"2022-03-09T23:41:51.489549Z","shell.execute_reply":"2022-03-09T23:41:51.509608Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"#train a support vector machine (SVM) classifier for embeddings\nSVMclf = SGDClassifier(loss=\"log\",penalty=\"l2\",alpha=1e-3).fit(x_train_embeddings, target)\n#predict test data with SVM classifier\nSVMpredict = SVMclf.predict(x_test_embeddings)\n#Read the sample_submission\nsample_submission=pd.read_csv(\"../input/nlp-getting-started/sample_submission.csv\")\nsample_submission[\"target\"]=SVMpredict\n#write the reults\nsample_submission.to_csv(\"./BERT_SVM.csv\",index=False)\n#results report\n#Use BERT to convert features from text and use SVM to classify target. \n#F1=0.81580","metadata":{"execution":{"iopub.status.busy":"2022-03-09T23:42:54.528858Z","iopub.execute_input":"2022-03-09T23:42:54.529273Z","iopub.status.idle":"2022-03-09T23:42:55.690501Z","shell.execute_reply.started":"2022-03-09T23:42:54.529242Z","shell.execute_reply":"2022-03-09T23:42:55.689323Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"#train a support vector machine (SVM) classifier for sparse feature matrix from bow\nSVMclfBow = SGDClassifier(loss=\"log\",penalty=\"l2\",alpha=1e-3).fit(x_train_counts, target)\n#predict test data with SVM classifier\nSVMpredictBow = SVMclfBow.predict(x_test_counts)\n#Read the sample_submission\nsample_submission=pd.read_csv(\"../input/nlp-getting-started/sample_submission.csv\")\nsample_submission[\"target\"]=SVMpredictBow\n#write the reults\nsample_submission.to_csv(\"./Bow_SVM.csv\",index=False)\n#results report\n#Use Bow to extract features from text and use SVM to classify target. \n#F1=0.79773","metadata":{"execution":{"iopub.status.busy":"2022-03-09T23:43:13.695965Z","iopub.execute_input":"2022-03-09T23:43:13.696261Z","iopub.status.idle":"2022-03-09T23:43:13.754940Z","shell.execute_reply.started":"2022-03-09T23:43:13.696229Z","shell.execute_reply":"2022-03-09T23:43:13.754015Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"#train a xgboost classifier for embeddings\nxgbr = xgb.XGBClassifier(max_depth=3,eta=0.6,objective='binary:logistic',reg_lambda=2)\nxgbr.fit(x_train_embeddings, target)\nscore = xgbr.score(x_train_embeddings, target)  \nprint(\"Training score: \", score)\nxgbpredict = xgbr.predict(x_test_embeddings)\nxgbpredict[0:10]\n#Read the sample_submission\nsample_submission=pd.read_csv(\"../input/nlp-getting-started/sample_submission.csv\")\nsample_submission[\"target\"]=xgbpredict\n#write the reults\nsample_submission.to_csv(\"./BERT_xgboost.csv\",index=False)\n#results report\n#Use BERT to convert features from text and use xgboost to classify target. \n#parameter setting:(max_depth=6,eta=0.6,objective='binary:logistic',reg_lambda=2)\n#Training score:  0.9722842506239328\n#Test F1=0.81581","metadata":{"execution":{"iopub.status.busy":"2022-03-09T23:48:27.185570Z","iopub.execute_input":"2022-03-09T23:48:27.185859Z","iopub.status.idle":"2022-03-09T23:48:59.409325Z","shell.execute_reply.started":"2022-03-09T23:48:27.185820Z","shell.execute_reply":"2022-03-09T23:48:59.408454Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n","output_type":"stream"},{"name":"stdout","text":"[23:48:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\nTraining score:  0.9722842506239328\n","output_type":"stream"}]},{"cell_type":"code","source":"#train a xgboost classifier for for sparse feature matrix from bow\nxgbrBow = xgb.XGBClassifier(max_depth=5,eta=0.6,objective='binary:logistic',reg_lambda=2)\nxgbrBow.fit(x_train_counts, target)\nscoreBow = xgbrBow.score(x_train_counts, target)  \nprint(\"Training score: \", scoreBow)\nxgbpredictBow = xgbrBow.predict(x_test_counts)\n#Read the sample_submission\nsample_submission=pd.read_csv(\"../input/nlp-getting-started/sample_submission.csv\")\nsample_submission[\"target\"]=xgbpredictBow\n#write the reults\nsample_submission.to_csv(\"./Bow_xgboost.csv\",index=False)\n#results report\n#Use Bow to extract features from text and use xgboost to classify target. \n#parameter setting:(max_depth=5,eta=0.6,objective='binary:logistic',reg_lambda=2)\n#Training score:  0.865493235255484\n#Test F1=0.78577","metadata":{"execution":{"iopub.status.busy":"2022-03-09T23:53:15.217653Z","iopub.execute_input":"2022-03-09T23:53:15.217969Z","iopub.status.idle":"2022-03-09T23:53:16.399098Z","shell.execute_reply.started":"2022-03-09T23:53:15.217934Z","shell.execute_reply":"2022-03-09T23:53:16.398060Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n","output_type":"stream"},{"name":"stdout","text":"[23:53:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\nTraining score:  0.865493235255484\n","output_type":"stream"}]},{"cell_type":"code","source":"#randomforest model for embeddings\nclf = RandomForestClassifier()\nclf.fit(x_train_embeddings, target)\n#predict test data\nrf_predict = clf.predict(x_test_embeddings)\n#Read the sample_submission\nsample_submission=pd.read_csv(\"../input/nlp-getting-started/sample_submission.csv\")\nsample_submission[\"target\"]=rf_predict\n#write the reults\nsample_submission.to_csv(\"./BERT_forest.csv\",index=False)\n#results report\n#Use BERT to convert features from text and use random.forest to classify target. \n#Test F1=0.81366","metadata":{"execution":{"iopub.status.busy":"2022-03-09T23:54:38.390816Z","iopub.execute_input":"2022-03-09T23:54:38.391547Z","iopub.status.idle":"2022-03-09T23:55:01.054117Z","shell.execute_reply.started":"2022-03-09T23:54:38.391480Z","shell.execute_reply":"2022-03-09T23:55:01.053409Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"#randomforest model for embeddings\nclfBow = RandomForestClassifier()\nclfBow.fit(x_train_counts, target)\n#predict test data\nrf_predictBow = clfBow.predict(x_test_counts)\n#Read the sample_submission\nsample_submission=pd.read_csv(\"../input/nlp-getting-started/sample_submission.csv\")\nsample_submission[\"target\"]=rf_predictBow\n#write the reults\nsample_submission.to_csv(\"./Bow_forest.csv\",index=False)\n#results report\n#Use Bow to convert features from text and use random.forest to classify target. \n#Test F1=0.78823","metadata":{"execution":{"iopub.status.busy":"2022-03-09T23:55:01.055921Z","iopub.execute_input":"2022-03-09T23:55:01.056394Z","iopub.status.idle":"2022-03-09T23:55:11.062350Z","shell.execute_reply.started":"2022-03-09T23:55:01.056350Z","shell.execute_reply":"2022-03-09T23:55:11.061503Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"#neural network from sklearn for embeddings\nclf = MLPClassifier(solver='lbfgs', alpha=1e-3, random_state=1,max_iter=2000)\nclf.fit(x_train_embeddings, target)\nsklearn_nn_predict=clf.predict(x_test_embeddings)\n#Read the sample_submission\nsample_submission=pd.read_csv(\"../input/nlp-getting-started/sample_submission.csv\")\nsample_submission[\"target\"]=sklearn_nn_predict\n#write the reults\nsample_submission.to_csv(\"./BERT_sklearn_nn.csv\",index=False)\n#results report\n#Use BERT to convert features from text and use neural network from sklearn to classify target. \n#Test F1=77566","metadata":{"execution":{"iopub.status.busy":"2022-03-09T23:15:04.48153Z","iopub.execute_input":"2022-03-09T23:15:04.481922Z","iopub.status.idle":"2022-03-09T23:15:54.000452Z","shell.execute_reply.started":"2022-03-09T23:15:04.481892Z","shell.execute_reply":"2022-03-09T23:15:53.999613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#define class for dataset, neural netword model, and train function\nclass traindata(Dataset):\n    def __init__(self, X, y):\n        if not torch.is_tensor(X) and not torch.is_tensor(y):\n            self.X = torch.from_numpy(X)\n            self.y = torch.Tensor(y)\n        else:\n            self.X = X\n            self.y = y\n        self.y = self.y.view(-1,1)\n    def __getitem__(self, i):\n        return self.X[i,], self.y[i]\n    def __len__(self):\n        return len(self.y)\n    \nclass DisasterNN(nn.Module):\n    def __init__(self,D_in,H,D_out):\n        super().__init__()\n        self.linear1=nn.Linear(D_in,H)\n        self.linear2=nn.Linear(H,D_out)\n    \n    def forward(self,x):\n        x=torch.sigmoid(self.linear1(x))\n        x=torch.sigmoid(self.linear2(x))\n        return x\n\ndef trainNN(trainset,modelNN,criterion,optimizer, epochs=50):\n    cost=[]\n    \n    for epoch in range(epochs):\n        total=0\n        \n        for X,y in trainloader:\n            optimizer.zero_grad()\n            yhat=modelNN(X)\n            loss=criterion(yhat,y)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            total+=loss.item()\n        \n        cost.append(total)\n    return cost  ","metadata":{"execution":{"iopub.status.busy":"2022-03-09T23:56:14.725395Z","iopub.execute_input":"2022-03-09T23:56:14.725664Z","iopub.status.idle":"2022-03-09T23:56:14.738031Z","shell.execute_reply.started":"2022-03-09T23:56:14.725637Z","shell.execute_reply":"2022-03-09T23:56:14.736783Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"#neural network from pytorch for embeddings\nmodelNN=DisasterNN(x_train_embeddings.shape[1],4,1)\ncriterion=nn.BCELoss()\noptimizer=torch.optim.SGD(modelNN.parameters(),lr=0.1)\ntrainset=traindata(x_train_embeddings,np.array(target))\ntrainloader=DataLoader(dataset=trainset,batch_size=10)\n#plot cost and print train score\nCOST=trainNN(trainset,modelNN,criterion,optimizer,epochs=2000)\nplt.plot(COST)\nprint(sum((modelNN(torch.tensor(x_train_embeddings))>0.5).int().view(-1).numpy()==target)/len(target))\nnnpredict=(modelNN(torch.tensor(x_test_embeddings))>0.5).int().view(-1).numpy()\n#Read the sample_submission\nsample_submission=pd.read_csv(\"../input/nlp-getting-started/sample_submission.csv\")\nsample_submission[\"target\"]=nnpredict\n#write the reults\nsample_submission.to_csv(\"./BERT_nn.csv\",index=False)\n#results report\n#Use BERT to convert features from text and use neural network to classify target. \n#Test F1=0.788","metadata":{"execution":{"iopub.status.busy":"2022-03-09T23:56:24.514862Z","iopub.execute_input":"2022-03-09T23:56:24.515183Z"},"trusted":true},"execution_count":null,"outputs":[]}]}